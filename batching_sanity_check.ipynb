{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geography_based_batched\n",
    "# import geography_based\n",
    "from datasets import *\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import fasttext\n",
    "from collections import Counter\n",
    "import re\n",
    "from countryinfo import CountryInfo\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.utils.data # changed to prevent namespace pollution\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pycountry\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize YFCC dataset to test batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsetting first 2000!\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([           \n",
    "        transforms.ToTensor(),                          \n",
    "        ])\n",
    "\n",
    "dataset = YfccPlacesDataset(transform_train, 10, num_data_alex = 2000)\n",
    "\n",
    "dataloader = data.DataLoader(dataset=dataset, \n",
    "              num_workers=0,\n",
    "              batch_size=1,\n",
    "              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define batched version of count_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_langs_batch(dataloader, batch_size = 64):\n",
    "    print(\"batch method, batch size: {0}\".format(batch_size))\n",
    "    mappings = pickle.load(open('country_lang_mappings.pkl', 'rb'))\n",
    "    iso3_to_lang = mappings['iso3_to_lang']\n",
    "    # Country to iso3 mappings that are missing\n",
    "    missing = {'South+Korea': 'KOR',\n",
    "            'North+Korea': 'PRK',\n",
    "            'Laos': 'LAO',\n",
    "            'Caribbean+Netherlands': 'BES',\n",
    "            'St.+Lucia': 'LCA',\n",
    "            'East+Timor': 'TLS',\n",
    "            'Democratic+Republic+of+Congo': 'COD',\n",
    "            'Swaziland': 'SWZ',\n",
    "            'Cape+Verde': 'CPV',\n",
    "            'C%C3%B4te+d%C2%B4Ivoire': 'CIV',\n",
    "            'Ivory+Coast': 'CIV',\n",
    "            'Channel+Islands': 'GBR'\n",
    "            }\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    \n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "\n",
    "    with_country = dataloader.dataset.with_country\n",
    "\n",
    "    country_with_langs = {}\n",
    "    country_with_imgs = {} # for each country, first list is tourist second is local\n",
    "    lang_counts = {}\n",
    "    \n",
    "    # arrays to cache data for batching speedup\n",
    "    batched_big_data =[]\n",
    "    batched_country_data=[]\n",
    "    batched_local_lang_data=[]\n",
    "    batched_target_data=[]\n",
    "    \n",
    "    \n",
    "    num_data = len(dataloader)\n",
    "\n",
    "    detecter = fasttext.load_model('lid.176.bin')\n",
    "    lang_dict = {}\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        if data is None:\n",
    "            continue\n",
    "        this_tags = [tag['label'] for tag in target[0] if len(tag['label']) >= 3]\n",
    "        if len(this_tags) > 0:\n",
    "            srcz = []\n",
    "            conf = []\n",
    "            for tag in this_tags:\n",
    "                classify = detecter.predict(tag)\n",
    "                srcz.append(classify[0][0][9:])\n",
    "                conf.append(classify[1][0])\n",
    "\n",
    "            # Pick out the most common language\n",
    "            commons = Counter(srcz).most_common()\n",
    "            the_src = commons[0][0]\n",
    "            # If the most common language is English, look at the second most common language\n",
    "            # since people oftentimes use English even when it's not their native language\n",
    "            if the_src == 'en' and len(commons) > 1:\n",
    "                the_src_maybe = commons[1][0]\n",
    "                words = [i for i in range(len(srcz)) if srcz[i] == the_src_maybe]\n",
    "                # If this second most common language has been classified with more than .5\n",
    "                # probability, then choose this language for the image\n",
    "                for word in words:\n",
    "                    if conf[word] > .5: \n",
    "                        the_src = the_src_maybe\n",
    "            if the_src in lang_counts.keys():\n",
    "                lang_counts[the_src] += 1\n",
    "            else:\n",
    "                lang_counts[the_src] = 1\n",
    "\n",
    "            country = target[2][0]\n",
    "            iso3 = None\n",
    "            local = None\n",
    "            try:\n",
    "                iso3 = pycountry.countries.search_fuzzy(country.replace('+', ' '))[0].alpha_3\n",
    "            except LookupError:\n",
    "                iso3 = missing[country]\n",
    "            try:\n",
    "                country_info = CountryInfo(country.replace('+', ' ')).info()\n",
    "            except KeyError:\n",
    "                country_info = {}\n",
    "            country_name = country.split('+')\n",
    "            if 'name' in country_info.keys():\n",
    "                country_name += country_info['name']\n",
    "            if 'nativeName' in country_info.keys():\n",
    "                country_name += country_info['nativeName']\n",
    "\n",
    "            # When comparing images to distinguish between tourist and local, we further look into the content of the tags,\n",
    "            # allowing some images to be categorized as 'unknown' if we are not that sure if it's tourist or local\n",
    "\n",
    "            # Local: in a local language, country's name isn't a tag, and 'travel' isn't a tag\n",
    "            # Tourist: in a non-local language, or 'travel' is a tag\n",
    "            try:\n",
    "                if the_src in iso3_to_lang[iso3] and len(set(country_name)&set(this_tags)) == 0 and 'travel' not in this_tags:\n",
    "                    local = 1\n",
    "                elif the_src not in iso3_to_lang[iso3] or 'travel' in this_tags:\n",
    "                    local = 0\n",
    "            except KeyError:\n",
    "                 print(\"This iso3 can't be found in iso3_to_lang: {}\".format(iso3))\n",
    "\n",
    "            if country not in country_with_langs.keys():\n",
    "                country_with_langs[country] = []\n",
    "                country_with_imgs[country] = [[], []]\n",
    "            country_with_langs[country].append(the_src)\n",
    "\n",
    "            if local is not None:\n",
    "                if len(country_with_imgs[country][local]) < 500:\n",
    "                    data = normalize(data).to(device)\n",
    "                    big_data = F.interpolate(data.unsqueeze(0), size=224, mode='bilinear').to(device)\n",
    "                    # cache these results for speedup \n",
    "                    batched_big_data.append(big_data)\n",
    "                    batched_country_data.append(country)\n",
    "                    batched_local_lang_data.append(local)\n",
    "                    batched_target_data.append(target[3])\n",
    "                    \n",
    "                    # run model on batched data\n",
    "                    if i % batch_size == 0 or i == num_data-1:\n",
    "                        all_big_data = torch.cat(batched_big_data, 0)\n",
    "                        batched_features = model.forward(all_big_data)\n",
    "                        for i, cur_feature in enumerate(batched_features):\n",
    "                            cur_country = batched_country_data[i]\n",
    "                            cur_local = batched_local_lang_data[i]\n",
    "                            cur_target = batched_target_data[i]\n",
    "                            country_with_imgs[cur_country][cur_local].append((cur_feature.data.cpu().numpy(), cur_target))\n",
    "\n",
    "                        batched_big_data =[]\n",
    "                        batched_country_data=[]\n",
    "                        batched_local_lang_data=[]\n",
    "                        batched_target_data=[]\n",
    "\n",
    "\n",
    "    info = {}\n",
    "    info['lang_counts'] = lang_counts\n",
    "    info['country_with_langs'] = country_with_langs\n",
    "    info['country_with_imgs'] = country_with_imgs\n",
    "    \n",
    "\n",
    "    pickle.dump(info, open(\"results/testing/batched_10.pkl\", \"wb\"))\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Old (unbatched) version of count_langs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_langs_old(dataloader):\n",
    "    mappings = pickle.load(open('country_lang_mappings.pkl', 'rb'))\n",
    "    iso3_to_lang = mappings['iso3_to_lang']\n",
    "    # Country to iso3 mappings that are missing\n",
    "    missing = {'South+Korea': 'KOR',\n",
    "            'North+Korea': 'PRK',\n",
    "            'Laos': 'LAO',\n",
    "            'Caribbean+Netherlands': 'BES',\n",
    "            'St.+Lucia': 'LCA',\n",
    "            'East+Timor': 'TLS',\n",
    "            'Democratic+Republic+of+Congo': 'COD',\n",
    "            'Swaziland': 'SWZ',\n",
    "            'Cape+Verde': 'CPV',\n",
    "            'C%C3%B4te+d%C2%B4Ivoire': 'CIV',\n",
    "            'Ivory+Coast': 'CIV',\n",
    "            'Channel+Islands': 'GBR'\n",
    "            }\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "\n",
    "    with_country = dataloader.dataset.with_country\n",
    "\n",
    "    country_with_langs = {}\n",
    "    country_with_imgs = {} # for each country, first list is tourist second is local\n",
    "    lang_counts = {}\n",
    "\n",
    "    detecter = fasttext.load_model('lid.176.bin')\n",
    "    lang_dict = {}\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        if data is None:\n",
    "            continue\n",
    "        this_tags = [tag['label'] for tag in target[0] if len(tag['label']) >= 3]\n",
    "        if len(this_tags) > 0:\n",
    "            srcz = []\n",
    "            conf = []\n",
    "            for tag in this_tags:\n",
    "                classify = detecter.predict(tag)\n",
    "                srcz.append(classify[0][0][9:])\n",
    "                conf.append(classify[1][0])\n",
    "\n",
    "            # Pick out the most common language\n",
    "            commons = Counter(srcz).most_common()\n",
    "            the_src = commons[0][0]\n",
    "            # If the most common language is English, look at the second most common language\n",
    "            # since people oftentimes use English even when it's not their native language\n",
    "            if the_src == 'en' and len(commons) > 1:\n",
    "                the_src_maybe = commons[1][0]\n",
    "                words = [i for i in range(len(srcz)) if srcz[i] == the_src_maybe]\n",
    "                # If this second most common language has been classified with more than .5\n",
    "                # probability, then choose this language for the image\n",
    "                for word in words:\n",
    "                    if conf[word] > .5: \n",
    "                        the_src = the_src_maybe\n",
    "            if the_src in lang_counts.keys():\n",
    "                lang_counts[the_src] += 1\n",
    "            else:\n",
    "                lang_counts[the_src] = 1\n",
    "\n",
    "            country = target[2][0]\n",
    "            iso3 = None\n",
    "            local = None\n",
    "            try:\n",
    "                iso3 = pycountry.countries.search_fuzzy(country.replace('+', ' '))[0].alpha_3\n",
    "            except LookupError:\n",
    "                iso3 = missing[country]\n",
    "            try:\n",
    "                country_info = CountryInfo(country.replace('+', ' ')).info()\n",
    "            except KeyError:\n",
    "                country_info = {}\n",
    "            country_name = country.split('+')\n",
    "            if 'name' in country_info.keys():\n",
    "                country_name += country_info['name']\n",
    "            if 'nativeName' in country_info.keys():\n",
    "                country_name += country_info['nativeName']\n",
    "\n",
    "            # When comparing images to distinguish between tourist and local, we further look into the content of the tags,\n",
    "            # allowing some images to be categorized as 'unknown' if we are not that sure if it's tourist or local\n",
    "\n",
    "            # Local: in a local language, country's name isn't a tag, and 'travel' isn't a tag\n",
    "            # Tourist: in a non-local language, or 'travel' is a tag\n",
    "            try:\n",
    "                if the_src in iso3_to_lang[iso3] and len(set(country_name)&set(this_tags)) == 0 and 'travel' not in this_tags:\n",
    "                    local = 1\n",
    "                elif the_src not in iso3_to_lang[iso3] or 'travel' in this_tags:\n",
    "                    local = 0\n",
    "            except KeyError:\n",
    "                 print(\"This iso3 can't be found in iso3_to_lang: {}\".format(iso3))\n",
    "\n",
    "            if country not in country_with_langs.keys():\n",
    "                country_with_langs[country] = []\n",
    "                country_with_imgs[country] = [[], []]\n",
    "            country_with_langs[country].append(the_src)\n",
    "            if local is not None:\n",
    "                if len(country_with_imgs[country][local]) < 500:\n",
    "                    data = normalize(data).to(device)\n",
    "                    big_data = F.interpolate(data.unsqueeze(0), size=224, mode='bilinear').to(device)\n",
    "                    this_features = model.forward(big_data)\n",
    "                    country_with_imgs[country][local].append((this_features.data.cpu().numpy(), target[3]))\n",
    "\n",
    "\n",
    "    info = {}\n",
    "    info['lang_counts'] = lang_counts\n",
    "    info['country_with_langs'] = country_with_langs\n",
    "    info['country_with_imgs'] = country_with_imgs\n",
    "    pickle.dump(info, open(\"results/testing/old_10.pkl\", \"wb\"))\n",
    "    return info\n",
    "    \n",
    "#     pickle.dump(info, open(\"results/{}/10.pkl\".format(args.folder), \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_res = count_langs_old(dataloader)\n",
    "batched_res = count_langs_batch(dataloader) # default batch size is 64\n",
    "\n",
    "\n",
    "# old_res = old_res[0]\n",
    "# batched_res = batched_res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if keys match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do keys match? {0}\".format(old_res.keys() == batched_res.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_res.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if 'lang_counts' match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_res['lang_counts'] == batched_res['lang_counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if 'country_with_langs' match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_res['country_with_langs'] == batched_res['country_with_langs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if country_with_images same with 0.01 element-wise tolerance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sum, new_sum = 0,0\n",
    "for country in old_res['country_with_imgs']:\n",
    "# for country in ['Japan']:\n",
    "    for local in range(2):\n",
    "        num_img_old = len(old_res['country_with_imgs'][country][local])\n",
    "        num_img_new = len(batched_res['country_with_imgs'][country][local])\n",
    "        num_images_match = num_img_old == num_img_new\n",
    "        if not num_images_match:\n",
    "            print(\"NUM IMAGES DONT MATCH\")\n",
    "        \n",
    "        for i in range(num_img_new):\n",
    "            # check if filepath is same\n",
    "            filepath_comp = old_res['country_with_imgs'][country][local][i][1] == batched_res['country_with_imgs'][country][local][i][1] \n",
    "            if not filepath_comp:\n",
    "                print(\"FILEPATHS DONT MATCH\")\n",
    "                \n",
    "            # check if feature array is elementwise same with 0.01 tolerance \n",
    "            old_feat = old_res['country_with_imgs'][country][local][i][0]\n",
    "            new_feat = batched_res['country_with_imgs'][country][local][i][0]\n",
    "            \n",
    "            allclose = np.allclose(old_feat, new_feat, atol = 0.01)\n",
    "            if not allclose:\n",
    "                print(\"Over threshold!\")\n",
    "#             print(\"element wise comparison thresh  = 0.01: {0}\".format(allclose))\n",
    "            \n",
    "#             print(np.sum(old_feat), np.sum(new_feat))\n",
    "            old_sum += np.sum(old_feat)\n",
    "            new_sum += np.sum(new_feat)\n",
    "            \n",
    "    print(\"old: sum of all img feature vecs for {0}: {1}\".format(country, old_sum))\n",
    "    print(\"batched: sum of all img feature vecs for {0}: {1}\".format(country, new_sum))\n",
    "    # check if sum of all feature elements is within 0.5 of each other\n",
    "    if np.abs(old_sum - new_sum) > 0.5:\n",
    "        print(\"difference in sum of feature vecs greater than 0.5\")\n",
    "    print(\"================================\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bottleneck is with text classification (which takes 99% time per iteration), so to show efficacy of batch operation on model() call, we provide dummy data to remove classification overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define batched version of function without classification overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_langs_batch_time(dataloader, batch_size = 64):\n",
    "    print(\"batch method, batch size: {0}\".format(batch_size))\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    \n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "\n",
    "\n",
    "    country_with_langs = {}\n",
    "    country_with_imgs = {} # for each country, first list is tourist second is local\n",
    "    lang_counts = {}\n",
    "    \n",
    "    # arrays to cache data for batching speedup\n",
    "    batched_big_data =[]\n",
    "    batched_country_data=[]\n",
    "    batched_local_lang_data=[]\n",
    "    batched_target_data=[]\n",
    "    \n",
    "    \n",
    "    num_data = len(dataloader)\n",
    "\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        country = \"dummy_country\"\n",
    "        local = 1\n",
    "        target = [\"dummy\", \"dummy\", \"dummy\", \"dummy\"]\n",
    "\n",
    "        the_src = \"en\"\n",
    "        if country not in country_with_langs.keys():\n",
    "            country_with_langs[country] = []\n",
    "            country_with_imgs[country] = [[], []]\n",
    "\n",
    "        country_with_langs[country].append(the_src)\n",
    "\n",
    "\n",
    "\n",
    "        if local is not None:\n",
    "            if len(country_with_imgs[country][local]) < 500:\n",
    "                data = normalize(data).to(device)\n",
    "                big_data = F.interpolate(data.unsqueeze(0), size=224, mode='bilinear').to(device)\n",
    "                # cache these results for speedup \n",
    "                batched_big_data.append(big_data)\n",
    "                batched_country_data.append(country)\n",
    "                batched_local_lang_data.append(local)\n",
    "                batched_target_data.append(target[3])\n",
    "\n",
    "                # run model on batched data\n",
    "                if i % batch_size == 0 or i == num_data-1:\n",
    "                    all_big_data = torch.cat(batched_big_data, 0)\n",
    "                    batched_features = model.forward(all_big_data)\n",
    "                    for i, cur_feature in enumerate(batched_features):\n",
    "                        cur_country = batched_country_data[i]\n",
    "                        cur_local = batched_local_lang_data[i]\n",
    "                        cur_target = batched_target_data[i]\n",
    "                        country_with_imgs[cur_country][cur_local].append((cur_feature.data.cpu().numpy(), cur_target))\n",
    "\n",
    "                    batched_big_data =[]\n",
    "                    batched_country_data=[]\n",
    "                    batched_local_lang_data=[]\n",
    "                    batched_target_data=[]\n",
    "\n",
    "\n",
    "    info = {}\n",
    "    info['lang_counts'] = lang_counts\n",
    "    info['country_with_langs'] = country_with_langs\n",
    "    info['country_with_imgs'] = country_with_imgs\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define old version of function without classification overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_langs_old_time(dataloader):\n",
    "    print(\"old method\")\n",
    "    \n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    \n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "\n",
    "    \n",
    "    \n",
    "    num_data = len(dataloader)\n",
    "    country_with_langs = {}\n",
    "    country_with_imgs = {} # for each country, first list is tourist second is local\n",
    "    lang_counts = {}\n",
    "    \n",
    "\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        country = \"dummy_country\"\n",
    "        local = 1\n",
    "        target = [\"dummy\", \"dummy\", \"dummy\", \"dummy\"]\n",
    "\n",
    "        the_src = \"en\"\n",
    "        if country not in country_with_langs.keys():\n",
    "            country_with_langs[country] = []\n",
    "            country_with_imgs[country] = [[], []]\n",
    "\n",
    "        country_with_langs[country].append(the_src)\n",
    "\n",
    "\n",
    "\n",
    "        if local is not None:\n",
    "            if len(country_with_imgs[country][local]) < 500:\n",
    "                data = normalize(data).to(device)\n",
    "                big_data = F.interpolate(data.unsqueeze(0), size=224, mode='bilinear').to(device)\n",
    "                feature = model.forward(big_data)\n",
    "                country_with_imgs[country][local].append((feature.data.cpu().numpy(), target[3]))\n",
    "\n",
    "\n",
    "\n",
    "    info = {}\n",
    "    info['lang_counts'] = lang_counts\n",
    "    info['country_with_langs'] = country_with_langs\n",
    "    info['country_with_imgs'] = country_with_imgs\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_time = []\n",
    "batch_time = []\n",
    "\n",
    "old_res = []\n",
    "batched_res = []\n",
    "\n",
    "for _ in range(3):\n",
    "    start = time.time()\n",
    "    old_res.append(count_langs_old_time(dataloader))\n",
    "    end = time.time()\n",
    "    old_time.append(end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    batched_res.append(count_langs_batch_time(dataloader))\n",
    "    end = time.time()\n",
    "    batch_time.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"old method avg time: {0}\".format(np.mean(old_time)))\n",
    "print(\"batched method avg time: {0}\".format(np.mean(batch_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing of model.forward depending on batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataloader, batch_size = 64):\n",
    "    '''\n",
    "    The goal of this function is to return a batch\n",
    "    of size batch_size as a torch tensor \n",
    "    of shape (batch_size, 3,3,224)\n",
    "    '''\n",
    "    print(\"batch method, batch size: {0}\".format(batch_size))\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    \n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "\n",
    "\n",
    "    # arrays to cache data for batching\n",
    "    batched_big_data =[]\n",
    "\n",
    "    \n",
    "    num_data = len(dataloader)\n",
    "\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        # early exit and return the batch\n",
    "        if i == batch_size:\n",
    "            print(\"batch obtained of size {0} obtained, returning\".format(batch_size))\n",
    "            all_big_data = torch.cat(batched_big_data, 0)\n",
    "            return all_big_data\n",
    "            \n",
    "\n",
    "        data = normalize(data).to(device)\n",
    "        big_data = F.interpolate(data.unsqueeze(0), size=224, mode='bilinear').to(device)\n",
    "        # cache these results\n",
    "        batched_big_data.append(big_data)\n",
    "\n",
    "        \n",
    "\n",
    "def timing_test(batch_data):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "    model.classifier = new_classifier\n",
    "    model.eval() # IMPORANT: turn off all model stochasticity for comparison\n",
    "    \n",
    "    time_arr = []\n",
    "    for _ in tqdm(range(1000)):\n",
    "        start = time.time()\n",
    "        #================================\n",
    "        feature = model.forward(batch_dat)\n",
    "        #================================\n",
    "        end = time.time()\n",
    "        time_arr.append(end-start)\n",
    "    return np.mean(time_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch method, batch size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/n/fs/revise-scr/alex/miniconda2/envs/toolenv/lib/python3.7/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "  5%|▌         | 100/2000 [00:02<00:40, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch obtained of size 100 obtained, returning\n",
      "beginning timing test, averaging over 1k executions of model.forward()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017628787755966185]\n",
      "================================\n",
      "batch method, batch size: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [00:10<01:30, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch obtained of size 200 obtained, returning\n",
      "beginning timing test, averaging over 1k executions of model.forward()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017628787755966185, 0.027569053649902343]\n",
      "================================\n",
      "batch method, batch size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/2000 [00:11<01:07, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch obtained of size 300 obtained, returning\n",
      "beginning timing test, averaging over 1k executions of model.forward()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:36<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017628787755966185, 0.027569053649902343, 0.03628393721580506]\n",
      "================================\n",
      "batch method, batch size: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/2000 [00:14<00:57, 27.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch obtained of size 400 obtained, returning\n",
      "beginning timing test, averaging over 1k executions of model.forward()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:49<00:00, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017628787755966185, 0.027569053649902343, 0.03628393721580506, 0.04908299827575684]\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "forward_time = []\n",
    "batch_sizes = [100, 200, 300, 400]\n",
    "for i in batch_sizes:\n",
    "    batch_dat = get_batch(dataloader, i)\n",
    "    print(\"beginning timing test, averaging over 1k executions of model.forward()\")\n",
    "    avg_execution_time = timing_test(batch_dat)\n",
    "    \n",
    "    forward_time.append(avg_execution_time)\n",
    "    print(forward_time)\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trend of batch size vs avg execution time of model.forward() call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find linear fit from data\n",
    "x = np.asarray(batch_sizes)\n",
    "\n",
    "m, b = np.polyfit(x, forward_time, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'average time per model() call vs batch size')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8deHECBAZF8S9n0JhMWgWHcFQQ1irV6wG7Zarm217a+3VG2tVdvb2mLrrVdbL1Zra2+r1VouRCwtRa11K1hI2BUQJCRsYScJZPn8/jgnYRgmIYEM2d7PxyMPzpzznXM+3znDfOYs8/2YuyMiIhKtRX0HICIiDZMShIiIxKQEISIiMSlBiIhITEoQIiISkxKEiIjEpAQhdcLMXjGzWfUdR0NmZpeZWW4N295vZr+NmvemmY0Lp79iZg/FKU43s8Hh9DNm9v14bCfW9uK8nTrpS3N6rytBSK3F+vBy96vd/df1FVNTZ2bTgEPuviKcNQ/4tJl1r8ew6p2ZbTGzSWdzm83pva4E0QSYWcv6jqExamSv2+3AsxUP3L0YeAX4bL1FJE2eEkScmdndZrbJzA6Z2Voz+3g4v7WZ7TezURFtu5lZUcW3QjPLNLOVYbu3zCw9ou0WM7vLzHKAI2bWsqpthe0TzOwnZrbHzD40szvCQ/uW4fIOZvaUmeWb2XYz+76ZJcToz1TgW8AMMztsZtnh/NfM7LZw+pbwdMgjYeybzexj4fxtZrYr8hA9fC0eNrOPzGynmT1hZklVvJ4V6/5vMztgZuvN7MqI5VX2IyquvcD9MdZ/v5m9YGa/DV/HVWY21MzuCePeZmZXRbRPNbMFZrbXzDaa2RciliWFpzX2mdlaYELUtlLN7I9mtjvcJ1+pos+tgCuA16MWvQZcG+s54fPSzOyvYWw7zexb4fzzzOztcN/km9lj4TZq7FTvXzPramZZYZu9ZvaGmVX3eXNN+D7ZY2ZzK9qa2SAzW2pmBeGy/zWzjuGyZ4G+wMLwvfjNcP5F4f+X/eH+uiViO53M7OVw375rZoOq6F+b8D1QEK5nmZn1CJdFvtezw21X/LmZXRYumxgRR3bF/EbF3fUXxz/gJiCVIBnPAI4AKeGyp4H/jGj7ZeDP4fR4YBdwPpAAzAK2AK3D5VuAlUAfIKkG27odWAv0BjoBSwAHWobL5wP/A7QDugP/BP69ij7dD/w2at5rwG3h9C1AKfC5MPbvAx8BjwOtgauAQ0D7sP1/AQuAzkAysBD4YRXbrlj3/wMSw34eADqfqh8Rz70TaFnxusXoWzEwJWzzG+BD4Nvh9r4AfBjR/nXg50AbYCywG7gyXPYQ8EbYrz7AaiA3XNYCeA+4D2gFDAQ2A1OiX2MgDTgSI9bxwN4qXqdkIB/4jzC2ZOD8cNm5wMSwf/2BdcDXIp7rwOBw+hng+1Vso7r37w+BJ8LXLBG4GLAq1uPAq+Hr1Bd4n+PvpcHA5PB90w34O/BfEc/dAkyKeNyX4L11c7jdLsDYiL7sBc4L+/6/wHNVxPTvBO/DtgTv4XOBc6Lf61HPmQ2sB84BegEFwDXhvp4cPu5W359Jtfr8qu8AmtsfwYf69HB6ErA5YtmbwGfD6V8A34t67gbg0nB6C/D5WmxrKREf+OG2PfyP0gM4SsQHZvgf7NUq1ns/p04QH0QsGx1uq0fEvAKCD1QjSGSDIpZdQMSHcNR2bgHyIj9sCJLAZ07Vj/C5H53iNbsf+GvE42nAYSAhfJwc9qUjwYd+GZAc0f6HwDPh9GZgasSy2RxPEOdHxwLcA/wq+jUGLgR2xIh1CFBWRT9uBlbU8D35NeBPEY9rmiCqe/8+CPxfxXpOsX2Pep2+BPytirbXR/aLkxPEPZF9iXruM8AvIx5fA6yvou3ngbeA9BjLXiMqQQAXEXyhGxo+vgt4NqrNYmBWTfZJQ/lrTOdgGyUz+yzwdYJvagDtga7h9FIgyczOB3YQfGD+KVzWD5hlZndGrK4VwRFChW212FZqVPvI6X4E37byzaxiXovo9dfSzojpIgB3j57XnuBbYVvgvYhtG8G3tqps9/B/XGgrQf9q0o+a9Ck6zj3uXhbZlzD2VIJv8IeiYskIp6Nf860R0/2AVDPbHzEvgeCII9o+gsQULZng6CmWPsCmWAvMbCjw0zDOtgRfEt6rYj3Vqe79O5cgyf0l3Bfz3L26u66iX6fUMNbuwKMERyDJBPtzXzXrqbLfoR0R04UE+zGWZ8N1PRee0vot8G13L4luaGZ9gD8QfPi/H87uB9xkwc0FFRIJjpQaDV2DiCMz6wc8CdwBdHH3jgSnGQzA3csJ3lg3A58EsiI+bLYRHL53jPhr6+6/j9iE13RbBKcbekc8t0/E9DaCb95dI7Z1jrunVdG1uhwCeA/Bh25axLY7uHtV/3EBellEBiA4rZBHzfpRl7HnAZ3NLPLDuy+wPZzO58TXuW/E9DaCo6TI/Zvs7tfE2M4HgJlZr6j5I4DsKmLbBsQ8v05wdLoeGOLu5xBcU7Iq2lapuvevux9y9/9w94EER2Ffj7xWFEP065QXTv+QYJ+lh7F+OirW6P1ZXb9rzN1L3P0Bdx8JfAzIJMYNARZcK5tPcNrrlag4no3av+1OkSQbHCWI+GpH8AbeDWBmnwNGRbX5HcF59E+F0xWeBG43s/Mt0M7Mro36MKrNtv4AfNXMeoXfiO6qWODu+cBfgJ+Y2Tlm1iK8OHhpFdvaCfQ/xUXHGgk/ZJ4EHrHjF+d7mdmUap7WHfiKmSWa2U0EH5SLTqMfZxr7NoLTED8ML2qmA7cSnNuG4DW/x8w6mVlvgmsfFf4JHLTgRoMkC24iGGVmJ1zIDrdTQnDNKLoflxLcyRRLFtDTzL4WXlBODr/pQ/BN/CBw2MyGA1+sdeePi/n+teAGi8FhIj9IcCquLPYqAJgTvk59gK8Cz0fEehjYHybIOVHP20lw/abC/wKTzOzfLLhxo4uZja1tp8zscjMbbcENDgeBkirif5rgNNWPo+b/FphmZlPCfdvGgt/B9I6xjgZLCSKO3H0t8BPgbYI38miC87SRbd4lOAefSsR/dndfTnBB9DGCQ+qNBOfQT3dbTxJ8eOYAK4BFBBdsK970nyU4hbU23N6LQEoVm3sh/LfAzP5VVUy1cBdB/94xs4MEH4bDqmn/LsH59z3AfwI3untBuKw2/agLNxOc0ssjOL3yXXf/a7jsAYLTJR8SvPaRt6mWEXyzHhsu3wP8EuhQxXb+h+A6CxDcZUNwDj3m/fjhN/nJ4TZ2EByFXB4u/gbBN/5DBO+L52Otoyaqev8S7J8lBB/ubwM/d/fXqlnV/xGc5loJvAw8Fc5/gOBi/IFw/ktRz/shcG94p9A33P0jgtflPwguSK8ExpxG13oSvHcOElzEf53gQz/aTODjUXcyXRx+eZhOcHS2m+CIYg6N7DPXTjyVK82FmV0NPOHu/eo7ltoIb1m8zd0vqu9YzjYz+wdwp7uvCK9N9XH3b9Z3XNJ06SJ1MxGeK72c4JtsD+C7HL+gKI1AZFJ09/+uz1ikeWhUhztyRozgcH0fwSmmdQT34IuIxKRTTCIiEpOOIEREJKYmcw2ia9eu3r9///oOQ0SkUXnvvff2uHu3WMuaTILo378/y5cvr+8wREQaFTPbWtUynWISEZGYlCBERCQmJQgREYmpyVyDEJGTlZSUkJubS3FxcX2HIvWsTZs29O7dm8TExBo/RwlCpAnLzc0lOTmZ/v37c+IAuNKcuDsFBQXk5uYyYMCAGj9Pp5hEmrDi4mK6dOmi5NDMmRldunSp9ZGkEoRIE6fkIHB67wMlCBERiUkJQkTiqn37oDhgXl4eN95441nd9tGjR5k0aRJjx47l+eef57bbbmPt2rUA/OAHPzirsTRGukgtImdFamoqL774Yly3UVpaSsuWxz/WVqxYQUlJCStXrgRgxowZlct+8IMf8K1vfSuu8TR2OoIQkbNiy5YtjBoVVMF95plnuOGGG5g6dSpDhgzhm988XvfoL3/5CxdccAHjx4/npptu4vDhwwA8+OCDTJgwgVGjRjF79mwqRqK+7LLL+Na3vsWll17Kz372s8r17Nq1i09/+tOsXLmSsWPHsmnTJi677DKWL1/O3XffTVFREWPHjuVTn/rUWXwVGhcdQYg0Ew8sXMPavIN1us6Rqefw3Wlpp/XclStXsmLFClq3bs2wYcO48847SUpK4vvf/z5LliyhXbt2/OhHP+KnP/0p9913H3fccQf33ReUMPnMZz5DVlYW06ZNA2D//v28/vrrJ6y/e/fu/PKXv+Thhx8mKyvrhGUPPfQQjz32WOWRhcSmBCEi9eLKK6+kQ4egBPfIkSPZunUr+/fvZ+3atVx44YUAHDt2jAsuuACAV199lR//+McUFhayd+9e0tLSKhNE5KkjqTtKECLNxOl+04+X1q1bV04nJCRQWlqKuzN58mR+//vfn9C2uLiYL33pSyxfvpw+ffpw//33n3BPf7t27c5a3M2JrkGISIMxceJE3nzzTTZu3AhAYWEh77//fmUy6Nq1K4cPH66Ti92JiYmUlJSc8XqasrgmCDObamYbzGyjmd0dY3lrM3s+XP6umfWPWJZuZm+b2RozW2VmbeIZq4jUv27duvHMM89w8803k56ezsSJE1m/fj0dO3bkC1/4AqNHj+b6669nwoQJZ7yt2bNnk56erovU1YhbTWozSwDeByYDucAy4GZ3XxvR5ktAurvfbmYzgY+7+wwzawn8C/iMu2ebWRdgv7uXVbW9jIwMV8EgkROtW7eOESNG1HcY0kDEej+Y2XvunhGrfTyPIM4DNrr7Znc/BjwHTI9qMx34dTj9InClBb8HvwrIcfdsAHcvqC45iIhI3YtngugFbIt4nBvOi9nG3UuBA0AXYCjgZrbYzP5lZt8kBjObbWbLzWz57t2767wDIiLNWTwTRKyRoaLPZ1XVpiVwEfCp8N+Pm9mVJzV0n+fuGe6e0a1bzJrbIiJymuKZIHKBPhGPewN5VbUJrzt0APaG81939z3uXggsAsbHMVYREYkSzwSxDBhiZgPMrBUwE1gQ1WYBMCucvhFY6sFV88VAupm1DRPHpcBaRETkrInbD+XcvdTM7iD4sE8Annb3NWb2ILDc3RcATwHPmtlGgiOHmeFz95nZTwmSjAOL3P3leMUqIiIni+vvINx9kbsPdfdB7v6f4bz7wuSAuxe7+03uPtjdz3P3zRHP/a27p7n7KHePeZFaRORsmj9/fuVw4QD33XcfS5YsOeP1rly5kkWLFlU+XrBgAQ899NAZr/dM6ZfUIiI1FJ0gHnzwQSZNmnTG641OENdddx13333Sb4vPOiUIEak0f8V2LnxoKQPufpkLH1rK/BXbz3id119/Peeeey5paWnMmzcPgF/84hcnDPH9zDPPcOeddwLwve99j+HDhzN58mRuvvlmHn744ZPWuXv3bj7xiU8wYcIEJkyYwJtvvgnAV77yFR588EEAFi9ezCWXXEJ5eXmV7Q8fPsznPvc5Ro8eTXp6On/84x+B40WOAF588UVuueUW3nrrLRYsWMCcOXMqhw+/5ZZbKof9+Nvf/sa4ceMYPXo0n//85zl69CgA/fv357vf/S7jx49n9OjRrF+//oS+HDt2jPvuu4/nn3++srDRM888wx133AHALbfcwhe/+EUuv/xyBg4cyOuvv87nP/95RowYwS233FK5nqqGST8j7t4k/s4991wXkROtXbu2xm3/9K9cH37vK97vrqzKv+H3vuJ/+lfuGcVQUFDg7u6FhYWelpbme/bs8V27dvmgQYMq20ydOtXfeOMNX7ZsmY8ZM8YLCwv94MGDPnjwYJ87d+5J67z55pv9jTfecHf3rVu3+vDhw93d/ciRIz5y5EhfunSpDx061Ddu3Fht+29+85v+1a9+tXK9e/fudXf3du3aVc574YUXfNasWe7uPmvWLH/hhRcql1U8Lioq8t69e/uGDRvc3f0zn/mMP/LII+7u3q9fP3/00Ufd3f3xxx/3W2+99aT+/OpXv/Ivf/nLMR/PmjXLZ8yY4eXl5T5//nxPTk72nJwcLysr8/Hjx/uKFSt89+7dfvHFF/vhw4fd3f2hhx7yBx544KTtxHo/EFwTjvm5qtFcRQSAuYs3UFRy4oAFRSVlzF28gevHRf/GteYeffRR/vSnPwGwbds2PvjgAyZOnMjAgQN55513GDJkCBs2bODCCy/kZz/7GdOnTycpKQmgcjjvaEuWLDnhVM/Bgwc5dOgQycnJPPnkk1xyySU88sgjDBo0qNr2S5Ys4bnnnquc36lTp9Pq44YNGxgwYABDhw4FYNasWTz++ON87WtfA+CGG24A4Nxzz+Wll16q9fqnTZuGmTF69Gh69OjB6NGjAUhLS2PLli3k5uZWOUz6mVCCEBEA8vYX1Wp+Tbz22mssWbKEt99+m7Zt23LZZZdVjsw6Y8YM/vCHPzB8+HA+/vGPY2aVVeJOpby8nLfffrsykURatWoVXbp0IS8v75Tt3Z1gdJ8TRc6LHFa8KqeKu2Jo84phzWur4vktWrQ4YZj0Fi1aUFpaSkJCQsxh0s+UrkGICACpHU/+sK1ufk0cOHCATp060bZtW9avX88777xTueyGG25g/vz5/P73v68s+HPRRRexcOFCiouLOXz4MC+/HPvu9quuuorHHnus8nFFZbitW7fyk5/8hBUrVvDKK6/w7rvvVts+ev6+ffsA6NGjB+vWraO8vLzy6AcgOTmZQ4cOnRTP8OHD2bJlS+Uw5c8++yyXXnppjV+nqtZbU1UNk36mlCBEBIA5U4aRlJhwwrykxATmTBl22uucOnUqpaWlpKen853vfIeJEydWLuvUqVNlJbnzzjsPgAkTJnDdddcxZswYbrjhBjIyMiqrzkV69NFHWb58Oenp6YwcOZInnngCd+fWW2/l4YcfJjU1laeeeorbbruN4uLimO0B7r33Xvbt28eoUaMYM2YMr776KhCUJM3MzOSKK64gJSWlcrszZ85k7ty5jBs3jk2bNlXOb9OmDb/61a+46aabGD16NC1atOD222+v8et0+eWXs3bt2sqL1LVV1TDpZypuw32fbRruW+RktR3ue/6K7cxdvIG8/UWkdkxizpRhZ3T94XQcPnyY9u3bU1hYyCWXXMK8efMYP14j7dSF2g73rWsQIlLp+nG9znpCiDZ79mzWrl1LcXExs2bNUnKoR0oQItKg/O53v6vvECSkaxAiTVxTOY0sZ+Z03gdKECJNWJs2bSgoKFCSaObcnYKCAtq0aVOr5+kUk0gT1rt3b3Jzc1HFRWnTpg29e/eu1XOUIESasMTERAYMGFDfYUgjpVNMIiISkxKEiIjEpAQhIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxBTXBGFmU81sg5ltNLO7YyxvbWbPh8vfNbP+4fz+ZlZkZivDvyfiGaeIiJwsbmMxmVkC8DgwGcgFlpnZAndfG9HsVmCfuw82s5nAj4AZ4bJN7j42XvGJiEj14nkEcR6w0d03u/sx4DlgelSb6cCvw+kXgSvNzOIYk4iI1FA8R3PtBWyLeJwLnF9VG3cvNbMDQJdw2QAzWwEcBO519zeiN2Bms4HZAH379q3b6EVEGrh41xCPZ4KIdSQQXbWkqjb5QF93LzCzc4H5Zpbm7gdPaOg+D5gHkJGRoYooItJszF+xnXteWkVRSRkA2/cXcc9LqwDqLEnE8xRTLtAn4nFvIK+qNmbWEugA7HX3o+5eAODu7wGbgKFxjFVEpFGZu3hDZXKoUFRSxtzFG+psG/FMEMuAIWY2wMxaATOBBVFtFgCzwukbgaXu7mbWLbzIjZkNBIYAm+MYq4hIo5K3v6hW809H3E4xhdcU7gAWAwnA0+6+xsweBJa7+wLgKeBZM9sI7CVIIgCXAA+aWSlQBtzu7nvjFauISGOT2jGJ7TGSQWrHpDrbhjWVYuYZGRm+fPny+g5DROSsiL4GAZCUmMAPbxhdq2sQZvaeu2fEWqZfUouINDKlZeV0ad+KMb07UPHDgF4dk2qdHE4lnncxiYhIHSkrd5Zt2UtWTh6vrNpBwZFjtG/dkuvH9uKG8b24eEi3Ot+mEoSISANVXu6s2LaPhdn5LFqVz65DR0lKTODKEd3JTE/lsmHdaJOYELftK0GIiDQg7k5O7gGycvJ4OSefvAPFtGrZgsuHdSMzPZUrR3Snbauz89GtBCEiUs/cnbX5B8nKyeflnHw+2ltIYoJxyZBuzJk6jEkjepDcJvGsx6UEISJSTz7YeYiFOflk5eSxefcREloYFw7uyh1XDGbKyJ50aHv2k0IkJQgRkbPowz1HyMrOIysnnw07D9HCYOLALtx20UCmjupJ53at6jvESkoQIiJxtm1vIVnhkcKavGBIuQn9O/HAdWlcPbon3ZPb1HOEsSlBiIjEQf6BIl7OyWdhTj7Z2/YDMLZPR+69dgTXpqeQ0qHufvEcL0oQIiJ1ZNehYhbl5JOVk8/yrfsAGNXrHO6+ejjXjk6hT+e29Rxh7ShBiIicgb1HjvHK6nwWZufx7od7cYfhPZP5xlVDuTY9lQFd29V3iKdNCUJEpJYOFJaweM0OFubk8damAsrKnYHd2vGVK4aQmZ7CkB7J9R1inVCCEBGpgUPFJfx17U6ycvJ544PdlJQ5fTu35d8vGUhmeiojUpJpahWTlSBERKpQeKyUJet2kZWdx2vv7+ZYaTm9OibxuQsHkJmewuheHZpcUoikBCEiEqG4pIxX1+8iKyefv63fSXFJOd2TW/Op8/uSmZ7KuD4dadGi6SaFSEoQItLsHS0t443397AwJ48la3dy5FgZXdq14sZze5OZnsqE/p1JaCZJIZIShIg0SyVl5by5cQ9ZOfksXrODQ8WldGybyLQxqWSmpzJxYGdaJjTvkjlKECLSbJSVO+9sLiArJ48/r97BvsISklu35Kq0nmSOSeGiwV1JbOZJIZIShIg0aeWVhXbyeWV1PnsOH6NdqwQmjexBZnoqlwztSuuW8aup0JgpQYhIk+Pu/Ouj/WTl5LFoVT47Dx6lTWILrhzeg8z0FC4f3j2uhXaaCiUIEWkS3J3V2w+SlROMlLp9fxGtElpw6bBuZKanMGlED9q11kdebejVEpFGy91Zv+NQZVLYWlBIyxbGxUO68vXJQ5mc1oNz6qHQTlOhBCEijc7GXYdYmB0Mn70pLLTzsUFd+NJlg5iS1pOObRtOTYXGTAlCRBqFLXuOVB4prN9xCDM4f0BnPnfhAK4e1ZMu7VvXd4hNjhKEiDRY2/YW8vKq4Ehh9fag0M65/Trx3WkjuWZ0Cj3OaZiFdpqKuCYIM5sK/AxIAH7p7g9FLW8N/AY4FygAZrj7lojlfYG1wP3u/nA8YxWRhmHHgWJeXhUMn70yLLQzpncHvn3NCK5JT6FXx4ZfaKepiFuCMLME4HFgMpALLDOzBe6+NqLZrcA+dx9sZjOBHwEzIpY/ArwSrxhFpGHYfegor6zOJys7n2Vbg5oKI1PO4ZtTh5E5OpW+XRpXoZ2mIp5HEOcBG919M4CZPQdMJzgiqDAduD+cfhF4zMzM3d3Mrgc2A0fiGKOI1JO9R47x59U7yMrJ453NBZQ7DO3Rnv83aSjXpqcwqFv7+g6x2YtngugFbIt4nAucX1Ubdy81swNAFzMrAu4iOPr4RlUbMLPZwGyAvn371l3kIhIXB4qCQjtZOfm8uXEPZeXOgK7t+PLlg8lMT2VYz6ZRaKepiGeCiDX0odewzQPAI+5+uLqx1t19HjAPICMjI3rdItIAHCouYcm6nWRl5/P3sNBO705JfOHigWSmp5CWek6TrqnQmMUzQeQCfSIe9wbyqmiTa2YtgQ7AXoIjjRvN7MdAR6DczIrd/bE4xisidaTwWClL1+9iYXYer24ICu2kdGjDrAv6kzkmlTG9m3ahnaYingliGTDEzAYA24GZwCej2iwAZgFvAzcCS93dgYsrGpjZ/cBhJQeRhq24pIzXNuwmKyePv63bRVFJGd2SW/PJ8/qSmZ7C+L6dmk2hnaYibgkivKZwB7CY4DbXp919jZk9CCx39wXAU8CzZraR4MhhZrziEZG6d6y0nDc+2E1WTj5/XbuTw0dL6dyuFR8f34vM9BTOH9ClWRbaaSos+MJeTQOz3gQf3BcDqUARsBp4GXjF3cvjHWRNZGRk+PLly+s7DJEmr6SsnLc2FZCVncfiNTs4WFzKOW1aMnVUTzLTU/nYoC7NvtBOY2Jm77l7Rqxl1R5BmNmvCO40yiL4jcIuoA0wFJgKfNvM7nb3v9dtyCLSkJSVO+9+WBDUVFiVz77CEtq3bslVI3uEhXa60aqlkkJTc6pTTD9x99Ux5q8GXjKzVoDuLxVpgsrLnfc+2sfC7DwWrdrBnsNHSUqsKLSTwqVDu6mmQhNXbYKIlRzMrBPQx91z3P0YsDFewYnI2eXurNy2n6ycfF7OyWfHwWJat2zB5cO6kzkmhSuGd6dtKw3h1lzUaE+b2WvAdWH7lcBuM3vd3b8ex9hE5Cxwd9bkHWRhTh4v5+STu6+IxATj0qHduPvq4Uwa2YMla3fyw0XrufN3K0jtmMScKcO4flyv+g5d4qymXwU6uPtBM7sN+JW7f9fMcuIZmIjE14Ydh1iYnUdWTh5bwkI7Fw7uylevHMJVaT3pkBQU2pm/Yjv3vLSKopIyALbvL+Kel1YBKEk0cTVNEC3NLAX4N+DbcYxHROJo0+7DZIWFdj7YdZgWBhcM6sK/XzqIqWk96dTu5EI7cxdvqEwOFYpKypi7eIMSRBNX0wTxIMHvGf7h7svMbCDwQfzCEpG68lFBIQvDQjvr8g9iBhP6deZ709OYOiqFbsnVF9rJ219Uq/nSdNQoQbj7C8ALEY83A5+IV1Aicma27y/i5TAp5OQeAGBc3458J3Mk145OoWeHmhfaSe2YxPYYySBVdRmavFP9DuJe4OfuvreK5VcAbd09Kx7BiUjN7TxYzMs5wemjf30UFNoZ3asD91w9nGvTU+jd6fRqKsyZMuyEaxAASYkJzJkyrE7ilobrVEcQq4CFZlYM/OAUckAAABcDSURBVAvYTfBDuSHAWGAJ8IO4RigiVdpz+CivrN7Bwuw8lm0JCu0M75nMnCnDuHZ0Cv27tjvjbVRcZ5i7eAN5+4t0F1MzcsqhNgDMbAhwIZBCMNTGOuDv7t5gTkJqqA1pLvYXVhTayeetTXsodxjUrR3TxqSSmZ7C4O6qqSA1d9pDbVRw9w/QRWmRenOwuIS/rNlJVk4e//hgD6XlTr8ubfniZYPITE9leM9kDZ8tdU4/iRRpoI4cLWXJup0szM7n7+/v5lhZOb06JnHrRQPITE9lVC8V2pH4UoIQaUCKjpWxdP0usnLyWLp+F0dLy+lxTms+PbEfmWNSGNeno5KCnDVKECL17GhpGa9vCGoqLFm3k8JjZXRt34oZE/qQmZ5KRj8V2pH6UdOxmIYCvwB6uPsoM0sHrnP378c1OpEm6lhpOW9u3MPCnDz+umYnh46W0rFtItPHppKZnsr5AzqrpoLUu5oeQTwJzAH+B8Ddc8zsd4AShEgNlZaV8/bmArKy8/nzmh0cKCohuU1LpozqSWZ6ChcO7kqikoI0IDVNEG3d/Z9R5z5L4xCPSJNSVu7888O9ZOXk8efVOyg4cox2rRKYPLIHmempXDy0K61bqqaCNEw1TRB7zGwQ4ABmdiOQH7eoRBqx8nJnxbZ9LMzOZ9GqfHYdOkqbxBZcOaIH09JTuGxYdxXakUahpgniy8A8YLiZbQc+BD4dt6hEGhl3Jyf3AFlhTYW8A8W0atmCy4Z2Y9qYVK4coUI70vjU9Idym4FJZtYOaOHuh+IblkjD5+6szT9YWX3to72FJCYYFw/pxjemDGPyyB4kt0ms7zBFTltN72LqCHwW6E9QGwIAd/9K3CITaaDe33mIrOxgpNTNe46Q0ML42KAu3HH5YKak9aRDWyUFaRpqesy7CHiHYPC+8viFI9IwfbjnCFnZeSzMyeP9nYcxg4kDunDrxQOYmtaTLu2rr6kg0hjVNEG0Uf1paW627S0kKxw+e03eQQAm9O/EA9elcfXonnRPrnlNBZHGqKYJ4lkz+wKQBRytmFlVnYgKZjYV+BmQAPzS3R+KWt4a+A1wLlAAzHD3LWZ2HsFFcQAD7nf3P9UwVpHTlre/iEWr8lmYk0/2tqCmwpg+Hbn32hFcMzpFRXKkWalpgjgGzCWoR10xPrgDA6t6gpklAI8Dk4FcYJmZLXD3tRHNbgX2uftgM5sJ/AiYAawGMty9NKyFnW1mC91dv72QOrfrUDGLcvLJysln+dZ9AKSlnsNdU4eTmZ5Cn86nV2hHpLGraYL4OjDY3ffUYt3nARvDO6Aws+eA6UBkgpgO3B9Ovwg8Zmbm7oURbdpwPCmJ1ImCsNBOVk4e734YFNoZ1iOZ/5g8lGvTUxjYrX19hyhS72qaINYAhadsdaJewLaIx7nA+VW1CY8WDgBdCH6Ydz7wNNAP+Eysowczmw3MBujbt28tw5Pm5kBhCYvX7GBhTh5vbSqgrNwZ2K0dd14xhGnpKQzpoUI7IpFqmiDKgJVm9ionXoOo7jbXWMNPRh8JVNnG3d8F0sxsBPBrM3vF3YtPaOg+j/BaRUZGho4y5CSHikv469qdZOXk88YHuykpc/p0TmL2JQPJTE9hZIpqKohUpaYJYn74Vxu5QJ+Ix72BvCra5JpZS6ADcMKFb3dfZ2ZHgFGAaorKKRUeK2XJul1kZefx2vu7OVZaTmqHNtzysf5kpqeS3ruDkoJIDdT0l9S/Po11LwOGmNkAYDswE/hkVJsFwCzgbeBGYKm7e/icbeFpp37AMGDLacQgzURxSRmvrt9FVk4+f1u/k+KScront+aT5/Vl2pgUxvVRTQWR2qo2QZjZH9z938xsFTEuFLt7elXPDT/c7wAWE9zm+rS7rzGzB4Hl7r4AeIrgFtqNBEcOM8OnXwTcbWYlBD/M+1ItL5BLM3C0tIw33g9qKixZu5Mjx8ro0q4VN57bm8z0VCb070yCkoLIaTP3qk/dm1mKu+eH3+JP4u5b4xZZLWVkZPjy5ToD1RTMX7GduYs3kLe/iNSOScyZMozrx/UCoKQsKLSTlZPP4jU7OFRcSoekRKam9WTamFQmDlShHZHaMLP33D0j1rJqjyDcvWJI7y+5+11RK/0RcNfJzxI5ffNXbOeel1ZRVFIGwPb9Rdz9xxze33mIfYXH+PPqHewrLCG5dUsmp/VgWnoqFw7uSquWSgoida2mF6knc3IyuDrGPJEzMnfxhsrkUKG4tJyfv7aJtq0SmDSiB5npKVwytJtqKojE2amuQXwR+BIw0MxyIhYlA2/GMzBpftyd7fuLqlz+3r2TSWqlpCBytpzqCOJ3wCvAD4G7I+YfOtU4TCI14e6s3n6QrJxg+Oyq9OqYpOQgcpad6hrEAeAAcPPZCUeaA3dn/Y5DlUlha0EhLVsYFw3pyqVDu/HSv3IpLj0+qnxSYgJzpgyrx4hFmifVQJSzZuOuQyzMDobP3rT7CC0MPjaoK1+8dBBT0nrSqV0rAM4b0LnKu5hE5OxRgpC42rLnSOWRwvodhzCD8/p35pYLB3D1qJ50jVFo5/pxvZQQRBoAJQipc7n7Cnk5HD571fYDAJzbrxPfnTaSa0an0OMcFdoRaQyUIKRO7DhQzMurgtNHKz4KC+307sC3rxnBNekp9FKhHZFGRwlCTtvuQ0d5ZXU+Wdn5LNsa1FQYkXIOc6YMIzM9hX5d2tV3iCJyBpQgpFb2Hgl+zZyVk8c7mwsodxjSvT1fu3IomWNSGKRCOyJNhhKEnNKBohL+smYHWTn5/GPjHsrKnQFd2/HlyweTmZ7KsJ4qtCPSFClBSEyHj5ayZO1OsnLy+Pv7ezhWVk7vTkl84eKg0E5aqgrtiDR1ShBSqfBYKUvX7yIrO59XN+ziaGk5KR3a8NkL+pE5JpUxKrQj0qwoQTRzxSVlvLZhN1k5efxt3S6KSsro2r41Myf0IXNMKuf2VaEdkeZKCaIZOlZazj827iYrO5+/rN3J4aOldG7Xio+P70VmegrnD+iiQjsiogTRXJSWlfPWpgKycvJYvGYnB4pKOKdNS64Z3ZPM9FQ+NqiLCu2IyAmUIJqwsnLn3Q8LyMrJ58+rd7D3yDHat27JVSN7kDkmhYsGd1OhHRGpkhJEE1Ne7rz30T6ysvNYtHoHuw8dJSkxgUkjg0I7l6rQjojUkBJEE+DuZOceYGF2HotW5ZN/oJjWLVtw+bDuZI5J4Yrh3WnbSrtaRGpHnxqNlLuzJu8gWTn5vLwqj217i0hMMC4d2o27pg5n0sgetG+t3Ssip0+fII3MhohCOx/uOULLFsaFg7vylSuGcFVaTzokJdZ3iCLSRChBNAKbdh8mKyy088Guw7QwuGBQF2ZfMpCpEYV2RETqkhJEA/VRQSFZq/JYmJ3PuvyDmMGE/p353vQ0po5KoVvyyYV2RETqkhJEA5K3vygstJNHdm5QaGdc3458J3Mk145OoWcHFdoRkbMnrgnCzKYCPwMSgF+6+0NRy1sDvwHOBQqAGe6+xcwmAw8BrYBjwBx3XxrPWOvLroMVhXbyeW/rPgBG9+rAPVcP59r0FHp3alvPEYpIcxW3BGFmCcDjwGQgF1hmZgvcfW1Es1uBfe4+2MxmAj8CZgB7gGnunmdmo4DFQJMpUrzn8FFeWb2DrOw8/rklKLQzvGcyc6YM49rRKfTvqkI7IlL/4nkEcR6w0d03A5jZc8B0IDJBTAfuD6dfBB4zM3P3FRFt1gBtzKy1ux+NY7xxtb+wotBOPm9vLqCs3BnUrR1fvXIImempDO6uQjsi0rDEM0H0ArZFPM4Fzq+qjbuXmtkBoAvBEUSFTwArYiUHM5sNzAbo27dv3UVeRw4Wl/DXNUFNhTc+2ENpudOvS1tuv3QgmempDO+ZrOGzRaTBimeCiPXJ57VpY2ZpBKedroq1AXefB8wDyMjIiF53vThytJQl63aSlZPP6xt2c6ysnF4dk7j1ogFkpqcyqpcK7YhI4xDPBJEL9Il43BvIq6JNrpm1BDoAewHMrDfwJ+Cz7r4pjnGeseKSsqDQTk4eS9fvoriknB7ntObTE/uROSaFcX06KimISKMTzwSxDBhiZgOA7cBM4JNRbRYAs4C3gRuBpe7uZtYReBm4x93fjGOMp+1oaRl/f38PC7PzWLJuJ4XHyujavhX/ltGHzPRUMvqp0I6ING5xSxDhNYU7CO5ASgCedvc1ZvYgsNzdFwBPAc+a2UaCI4eZ4dPvAAYD3zGz74TzrnL3XfGKtyZKysr5x8Y9YaGdHRwqLqVT20Smj+3FtPQUzh+oQjsi0nSYe4M4dX/GMjIyfPny5bV+3vwV25m7eAN5+4tI7ZjEnCnDuH7c8TtqS8vKeWfzXrJy8vjzmh3sLwwK7UxJ60nmmKDQTqIK7YhII2Vm77l7RqxlzfqX1PNXbOeel1ZRVFIGwPb9Rdzz0irKy53UTklBUli9gz2Hj9GuVQKTR/YgMz2Vi4d2pXVL1VQQkaatWSeIuYs3VCaHCkUlZXzjxWzKHZISE7hiRHempadw2bDuKrQjIs1Ks04QefuLYs4vd/jvm8dx5QgV2hGR5qtZnzxP7ZgUc36vjklMG5Oq5CAizVqzThBzpgwjKeq0UVJiAnOmDKuniEREGo5m/RW54m6l6u5iEhFprpp1goAgSSghiIicrFmfYhIRkaopQYiISExKECIiEpMShIiIxKQEISIiMSlBiIhITEoQIiISkxKEiIjEpAQhIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxKQEISIiMcU1QZjZVDPbYGYbzezuGMtbm9nz4fJ3zax/OL+Lmb1qZofN7LF4xigiIrHFLUGYWQLwOHA1MBK42cxGRjW7Fdjn7oOBR4AfhfOLge8A34hXfCIiUr14HkGcB2x0983ufgx4Dpge1WY68Otw+kXgSjMzdz/i7v8gSBQiIlIP4pkgegHbIh7nhvNitnH3UuAA0KWmGzCz2Wa23MyW7969+wzDFRGRSPFMEBZjnp9Gmyq5+zx3z3D3jG7dutUqOBERqV48E0Qu0CficW8gr6o2ZtYS6ADsjWNMIiJSQ/FMEMuAIWY2wMxaATOBBVFtFgCzwukbgaXuXuMjCBERiZ+W8Vqxu5ea2R3AYiABeNrd15jZg8Byd18APAU8a2YbCY4cZlY838y2AOcArczseuAqd18br3hFROREcUsQAO6+CFgUNe++iOli4KYqnts/nrGJiEj19EtqERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYlJCUJERGJSghARkZiUIEREJCYlCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYlJCUJERGJSghARkZiUIEREJCYlCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJydy9vmOoE2a2G9h6BqvoCuypo3DqU1PpB6gvDVFT6QeoLxX6uXu3WAuaTII4U2a23N0z6juOM9VU+gHqS0PUVPoB6ktN6BSTiIjEpAQhIiIxKUEcN6++A6gjTaUfoL40RE2lH6C+nJKuQYiISEw6ghARkZiUIEREJKZmkSDM7Gkz22VmqyPmdTazv5rZB+G/ncL5ZmaPmtlGM8sxs/H1F/nJqujL/Wa23cxWhn/XRCy7J+zLBjObUj9Rn8zM+pjZq2a2zszWmNlXw/mNbr9U05fGuF/amNk/zSw77MsD4fwBZvZuuF+eN7NW4fzW4eON4fL+9Rl/hWr68YyZfRixT8aG8xvs+6uCmSWY2Qozywofx3+fuHuT/wMuAcYDqyPm/Ri4O5y+G/hROH0N8ApgwETg3fqOvwZ9uR/4Roy2I4FsoDUwANgEJNR3H8LYUoDx4XQy8H4Yb6PbL9X0pTHuFwPah9OJwLvh6/0HYGY4/wngi+H0l4AnwumZwPP13YdT9OMZ4MYY7Rvs+ysixq8DvwOywsdx3yfN4gjC3f8O7I2aPR34dTj9a+D6iPm/8cA7QEczSzk7kZ5aFX2pynTgOXc/6u4fAhuB8+IWXC24e767/yucPgSsA3rRCPdLNX2pSkPeL+7uh8OHieGfA1cAL4bzo/dLxf56EbjSzOwshVulavpRlQb7/gIws97AtcAvw8fGWdgnzSJBVKGHu+dD8B8c6B7O7wVsi2iXS/X/2RuKO8JD46crTsvQSPoSHgKPI/iW16j3S1RfoBHul/BUxkpgF/BXgiOc/e5eGjaJjLeyL+HyA0CXsxtxbNH9cPeKffKf4T55xMxah/Ma9D4B/gv4JlAePu7CWdgnzTlBVCVWpm3o9wL/AhgEjAXygZ+E8xt8X8ysPfBH4GvufrC6pjHmNfS+NMr94u5l7j4W6E1wZDMiVrPw3wbbl+h+mNko4B5gODAB6AzcFTZvsP0ws0xgl7u/Fzk7RtM63yfNOUHsrDiEDP/dFc7PBfpEtOsN5J3l2GrF3XeG/xnKgSc5frqiQffFzBIJPlD/191fCmc3yv0Sqy+Ndb9UcPf9wGsE5+Q7mlnLcFFkvJV9CZd3oOanQM+KiH5MDU8HursfBX5F49gnFwLXmdkW4DmCU0v/xVnYJ805QSwAZoXTs4D/i5j/2fCuhonAgYpTHg1V1LnSjwMVdzgtAGaGdzUMAIYA/zzb8cUSnhN9Cljn7j+NWNTo9ktVfWmk+6WbmXUMp5OASQTXVF4FbgybRe+Xiv11I7DUw6uj9amKfqyP+PJhBOfsI/dJg3x/ufs97t7b3fsTXHRe6u6f4mzsk7N9Jb4+/oDfExzilxBk11sJzsn9Dfgg/LezH7/74XGC866rgIz6jr8GfXk2jDUnfHOkRLT/dtiXDcDV9R1/RFwXERz25gArw79rGuN+qaYvjXG/pAMrwphXA/eF8wcSJLGNwAtA63B+m/DxxnD5wPruwyn6sTTcJ6uB33L8TqcG+/6K6tdlHL+LKe77RENtiIhITM35FJOIiFRDCUJERGJSghARkZiUIEREJCYlCBERiUkJQpo1M+tvESPj1vA5t5hZag3aPHaaMd1uZp89neeK1KWWp24iIlFuIbiPPi6/tHX3J+KxXpHa0hGECLQ0s1+HA7i9aGZtAczsPjNbZmarzWxe+CvbG4EM4H/DegJJZjbBzN6yoPbAP80sOVxvqpn9ORyv/8exNmxmD5nZ2nDbD4fz7jezb5hZqh2vW7DSzMrMrF/4K+E/hrEtM7MLz8qrJM2OEoQIDAPmuXs6cJBgPH2Ax9x9gruPApKATHd/EVgOfMqDgeDKgOeBr7r7GIIhHYrC548FZgCjgRlmFjnWD2bWmWAIjrRw29+PXO7uee4+NtzOk8Af3X0r8DPgEXefAHyCcAhokbqmBCEC29z9zXD6twRDZwBcHlbkWkUwQFpajOcOA/LdfRmAux/040Mw/83dD7h7MbAW6Bf13INAMfBLM7sBKIwVXHiEcBvw+XDWJOCxcCjrBcA5EUctInVG1yBETh4K2c2sDfBzgjF5tpnZ/QRj3ESzGM+vcDRiuoyo/2/uXmpm5wFXEgzCdgdBIjq+8mBwuaeA6/x4AZwWwAXuXoRIHOkIQgT6mtkF4fTNwD84ngz2hHUeboxof4igtCjAeoJrDRMAzCw5YgjmaoXr7eDui4CvEZySilyeSFBW8i53fz9i0V8IkklFuxOeJ1JXlCBEguGsZ5lZDkERmV94UEPgSYKRPecDyyLaPwM8EZ7iSSC4zvDfZpZNUIEt1pFGLMlAVrjd14H/F7X8YwSFbR6IuFCdCnwFyAgvbK8Fbq91j0VqQKO5iohITDqCEBGRmJQgREQkJiUIERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYnp/wM6mKR/br5JwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, forward_time, label = \"avg execution time\")\n",
    "plt.plot(x, x*m+b, label=\"linear fit\")\n",
    "plt.xlabel(\"batch size\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.title(\"average time per model() call vs batch size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
